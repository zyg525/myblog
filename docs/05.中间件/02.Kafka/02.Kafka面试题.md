---
title: Kafka面试题
tags: 消息中间件
layout: post
categories: 十五、消息中间件
date: 2024-03-30 14:04:37
permalink: /pages/ffc9b7/
author: 
  name: xugaoyi
  link: https://github.com/xugaoyi
---



## 1、使用消息中间件有什么优点和缺点？

　　主要有三点好处：

　　**1、异步执行任务**：假如系统A要向系统B发送消息，如果没有消息中间件，系统A必须等待系统B处理完消息后才能继续运行，而有了消息中间件，系统A可以直接把消息放到消息中间件中，然后去执行自己的任务，系统B怎么消费消息自己决定。

　　**2、解耦**：假如系统A要向系统B发送消息，系统B如果出现故障，会影响系统A的运行，有了消息中间件后，系统B只和消息中间件打交道，不会影响系统A的运行。

　　**3、削峰填谷**：假如系统A要向系统B发送消息，而系统A发送消息的数量远大于系统B所能处理的数量，这就会给系统A和B造成很大压力，而有了消息中间件后，系统A可以把消息保存到消息中间件中，而不用考虑系统B的处理能力，系统B也可以按照自己的能力处理这些消息。

　　缺点主要是：

　　**1、系统复杂度升高、可用性降低。**

## 2、Kafka是如何实现高可用的？

　　**1、一个主题多个节点：**Kafka的一个主题中有多个分区，这些分区可以分布在多个节点上，这样当某个节点出现故障时，还有其它分区可以使用。

　　**2、分区副本：**Kafka的每个分区都有自己的**副本**，这些副本也可以分布在多个节点上。我们把最开始的分区叫做主分区，把这些副本叫做副本分区，生产者和消费者只和主分区打交道。**生产消息时**，生产者向主分区发送消息，副本分区会同步主分区的消息，当主分区和副本分区都收到消息后，主分区才会返回成功的消息给生产者。**消费消息时**，只有被主分区、副本分区都同步过的消息才会被消费。如果某个副本**分区不可用**了，还有主分区和其它副本分区可以使用，而如果主分区不可用了，就会从副本分区中选举出一个主分区。

## 3、怎样保证Kafka消息不被重复消费（如何保证消息消费时的幂等性）？

　　**Kafka会在以下情况下出现消息重复消费：**

　　Kafka中每个分区内的消息都有一个偏移量`offset`，它代表了这条消息在分区中的位置，消费者每隔几秒就会把当前消费到的偏移量提交给Kafka，这样当消费者重启或被更换后，就可以从上一次消费到的位置开始消费。但是如果消费者还没来得及提交偏移量就出现问题，此时提交的偏移量不是最新的，当消费者重启或被更换后，就会造成重复消费。可以通过减少提交间隔来减少重复消费的数量，但不能完全避免重复消费，所以关键是发生重复消费后如何保证幂等性。

　

　　**保证消息消费时的幂等性的方法主要有：**

　　**1、利用数据库的唯一约束：**比如向MySQL插入数据时，消息中携带主键，插入的时候使用`INSERT INTO IF NOT EXIST`，就可以避免因重复插入导致的主键冲突，在MySQL中的写法是`INSERT INTO ... ON DUPLICATE KEY UPDATE ...`(如果主键冲突则更新)。再比如Redis中的key是不能重复的，因此不管`SET`多少次相同的消息都不影响结果。

　　**2、自定义唯一ID：**我们还可以给消息添加一个唯一ID，每次消费后都把消息的唯一ID保存到数据库中，每次消费前都去数据库中查询ID是否已经存在了，如果不存在才进行消费。

## 4、怎样保证Kafka消息的可靠性（如何处理消息丢失的问题）？

　　一条消息从生产到消费，可以划分为三个阶段：**生产阶段->存储阶段->消费阶段。**要保证消息不丢失，就要保证消息在这三个阶段都不丢失。

　　**1、保证消息在存储阶段不丢失**

　　Kafka的副本机制是消息在存储阶段可靠性的保证。每个分区都可以有多个副本，这些副本分布在不同的节点上，关于分区副本有三个参数可以影响消息的可靠性：

- `replication.factor`：副本数量，包括主分区和副本分区。副本数量越多，数据可靠性越高，但副本同步的代价也越大，降低了系统的可用性。
- `unclean.leader.election.enable`：是否支持不同步的副本分区参与选举主分区。如果支持，那么当主分区不可用，并且所有副本分区都没有同步完成主分区的数据时，会将其中一个副本分区选举为主分区，而新主分区会丢失掉旧主分区的消息。为了保证消息不丢失，这个参数应该改成`false`，这样当主分区不可用，并且所有副本分区都没有同步完成主分区的数据时，不会马上选举出一个主分区，而是会等待原来的主分区重新上线，这期间服务不可用，因此虽然保证了消息不丢失，但是降低了系统可用性。
- `min.insync.replicas`：消息至少要被写入到多少个分区才算是已提交，包括主分区和副本分区。只有已提交的消息，生产者才会看作是发送成功，否则就会重试或者抛异常。这个参数值越大，数据的可靠性越高，但是如果这个参数等于副本数量时，就要求消息被写入所有分区后才算是已经提交，此时如果有一个分区不可用，所有分区就都不可用了。为了兼顾消息可靠性和系统可用性，建议设置成`min.insync.replicas = replication.factor - 1`。

　

　　**2、保证消息在生产阶段不丢失**

　　在生产阶段保证消息不丢失的方法如下：

- **使用异步回调方法：**使用异步回调方法发送消息，可以获取到消息发送成功或失败的响应，然后针对性地进行处理。比如对于偶尔发送的错误，比如由于网络不稳定导致发送失败，就可以尝试重新发送。
- **ACK（生产者确认）：**ACK是生产者的确认模式，它有三个参数：`ACKS = 0`、`ACKS = 1`、`ACKS = all`，0表示生产者不会等待Broker的反馈，1表示生产者只会等待主分区的反馈，all表示生产者会等待主分区和所有副本分区的反馈。0和1都会造成消息丢失，all可以保证消息不丢失，但是会降低吞吐量。
- **重试：**可以使用`retries`参数来设置重试次数，这样当消息发送失败时，会重试一定次数，对于因网络波动导致的发送失败，这种处理办法是可以解决的。还有一些错误无法通过重试解决，比如消息大小错误、认证错误、序列化错误、重试次数达到上限等，就需要开发者自己处理了。

　

　　**3、保证消息在消费阶段不丢失**

　　消息在消费阶段丢失的主要原因是，消费者提交了偏移量之后，消息还没有处理完，消费者就不可用了。**解决办法是关闭偏移量的自动提交，在确认消息处理完后手动提交偏移量。**

　　手动提交偏移量有同步提交和异步提交两种方式，同步提交会造成线程阻塞，当提交失败时会不断重试，直到无法重试，这会大大限制吞吐量；异步提交不会阻塞线程，提交失败时也不会重试，原因是重试可能会导致新提交的偏移量被旧提交的偏移量覆盖，造成重复消费。实际上偏移量偶尔提交失败影响不大，只要保证消费者关闭或者分区再均衡之前的最后一次提交偏移量成功即可。**因此可以采用异步提交和同步提交的组合方式提交偏移量。**

　　代码如下：

```java
// 关闭自动提交偏移量
properties.put("enable.auto.commit", false);
try {
    while (true) {
        ConsumerRecords<String, String> consumerRecords = kafkaConsumer.poll(100);
        for (ConsumerRecord<String, String> consumerRecord : consumerRecords) {
            ...
        }
        // 异步提交偏移量，提高吞吐量
        kafkaConsumer.commitAsync();
    }
}finally {
    try {
        // 最后一次提交使用同步提交，确保偏移量提交成功
        kafkaConsumer.commitSync();
    }finally {
        kafkaConsumer.close();
    }
}
```

## 5、怎样保证消息的有序性？

　　保证消息有序性的方法是：

　　为消息指定一个key，相同key的消息会发送到同一个分区中，分区内的消息是有序的。在消费者端可以为每个key创建一个线程进行消费，线程内部的消息就是有序的。

## 6、怎么处理消息积压问题？

　　消息积压一般是因为消费者的处理速度太慢导致的。解决办法是：

　　1、关闭原来的消费者；

　　2、创建一个新的topic，分区数量是原来的10倍；

　　3、临时写一个分发消息的消费者程序，把旧topic中的数据导入新topic；

　　4、再临时写一个处理消息的消费者程序，线程数量也是原来的10倍，每个程序负责消费一个分区；

　　5、处理完积压的消息后，再修复原来的消费者程序。



